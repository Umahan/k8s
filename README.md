# Kubernetes Production Deployment with HPA

![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![Production-Ready](https://img.shields.io/badge/Production-Ready-success?style=for-the-badge)
![Auto-Scaling](https://img.shields.io/badge/Auto--Scaling-Enabled-blue?style=for-the-badge)

## üìã Table of Contents
- [Project Overview](#-project-overview)
- [Repository Structure](#-repository-structure)
- [Features & Best Practices Implemented](#-features--best-practices-implemented)
- [Files Description](#-files-description)
- [Deployment Instructions](#%EF%B8%8F-deployment-instructions)
- [Security & Compliance](#-security--compliance)
- [Summary](#-summary)
- [Troubleshooting Tips](#-troubleshooting-tips)

## üåê Project Overview 

<details> <summary><b>üîß Click to expand description </b></summary>


### English

#### Environment & Application Profile

Our application operates within a multi-zone Kubernetes cluster spanning three availability zones, comprising a total of five worker nodes.

#### Key Application Characteristics:

- **Initialization:** Requires a 5-10 second startup period.
- **Performance & Scaling:** Load testing confirms that four pod replicas are sufficient to handle the projected peak traffic load.
- **Resource Utilization Pattern:**
      - **CPU:** Exhibits a significant spike during the initial request processing, subsequently stabilizing at a consistent baseline of approximately 0.1 CPU cores.
      - **Memory:** Consumption is stable and predictable, consistently around 128 MiB.
- **Traffic Pattern:** Features a distinct diurnal cycle, with daytime peak traffic exceeding nighttime load by an order of magnitude.

#### Deployment Objectives:
- **Maximize Resilience:** Achieve the highest possible level of fault tolerance and availability within the given cluster topology.
- **Optimize Resource Efficiency:** Minimize the total resource footprint of the deployment while fully meeting performance and scalability requirements.

### –†—É—Å—Å–∫–∏–π

#### –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ –≤ –º—É–ª—å—Ç–∏–∑–æ–Ω–∞–ª—å–Ω–æ–º Kubernetes-–∫–ª–∞—Å—Ç–µ—Ä–µ, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º –ø–æ —Ç—Ä—ë–º –∑–æ–Ω–∞–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –Ω–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏–∑ –ø—è—Ç–∏ —É–∑–ª–æ–≤.

#### –ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:

- **–í—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:** 5‚Äì10 —Å–µ–∫—É–Ω–¥.
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å:** –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∏–∫–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–µ—Ç—ã—Ä—ë—Ö —Ä–µ–ø–ª–∏–∫ Pod.
- **–ü–∞—Ç—Ç–µ—Ä–Ω –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤:**
  - **CPU:** –ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–π –≤—Å–ø–ª–µ—Å–∫ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–µ—Ä–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–µ–π –Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–º —É—Ä–æ–≤–Ω–µ –æ–∫–æ–ª–æ 0.1 —è–¥—Ä–∞.
  - **–ü–∞–º—è—Ç—å:** –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–π–æ–Ω–µ 128 MiB.
- **–ü—Ä–æ—Ñ–∏–ª—å –Ω–∞–≥—Ä—É–∑–∫–∏:** –ù–∞–≥—Ä—É–∑–∫–∞ –∏–º–µ–µ—Ç —è—Ä–∫–æ –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–π —Å—É—Ç–æ—á–Ω—ã–π —Ü–∏–∫–ª: –¥–Ω–µ–≤–Ω–æ–π –ø–∏–∫ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –Ω–æ—á–Ω—É—é –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ –ø–æ—Ä—è–¥–æ–∫.

#### –¶–µ–ª–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Deployment:
- **–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å:** –û–±–µ—Å–ø–µ—á–∏—Ç—å –±–µ—Å–ø–µ—Ä–µ–±–æ–π–Ω—É—é —Ä–∞–±–æ—Ç—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–∑–æ–Ω–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏.
- **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ—Å—É—Ä—Å–æ–≤:** –°–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SLA –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, –∞–¥–∞–ø—Ç–∏—Ä—É—è—Å—å –∫ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–∞–º –Ω–∞–≥—Ä—É–∑–∫–∏.

</details>

## üìÅ Repository Structure

~~~
umahan-k8s/
‚îú‚îÄ‚îÄ README.md # Project documentation
‚îú‚îÄ‚îÄ autoscaler.yaml # Horizontal Pod Autoscaler configuration
‚îú‚îÄ‚îÄ deployment.yaml # Production-grade Deployment configuration
‚îî‚îÄ‚îÄ service.yaml # Service definition (to be implemented)
~~~

## üöÄ Features & Best Practices Implemented

<details> <summary><b> Click here to expand</b></summary>

### 1. **Intelligent Auto-Scaling** (`autoscaler.yaml`)
- **Multi-version HPA (v2)** for advanced metrics support
- **Dual-direction scaling policies** with different stabilization windows
- **CPU utilization target** set at 70% for optimal resource usage
- **Conservative scale-down** (50% max per minute) to prevent thrashing
- **Aggressive scale-up** (100% per 30 seconds) for rapid response to traffic spikes

### 2. **Production-Ready Deployment** (`deployment.yaml`)
- **Rolling Update Strategy** with zero-downtime deployments
- **Topology Spread Constraints** for high availability across zones
- **Pod Anti-Affinity** rules to avoid single-node failures
- **Comprehensive Health Probes** (startup, readiness, liveness)
- **Security Hardening** with non-root execution and capability restrictions

### 3. **Resource Optimization**
- **Memory Optimization** with 15% buffer for JVM applications
- **CPU Request/Limit Balance** for cost-efficiency and burst handling
- **Efficient Scaling Range** (1-4 pods) based on load testing

</details>

---

## üìã Files Description

<details> <summary><b> Click here to expand description </b></summary>

### `deployment.yaml`
**Purpose:** Defines the web application deployment with production-grade configurations.

**Key Features:**
- **Rolling Updates:** `maxSurge: 1, maxUnavailable: 0` for zero-downtime deployments
- **High Availability:** Pod distribution across zones and nodes
- **Health Monitoring:** Three-tier probe system (startup, readiness, liveness)
- **Security:** Non-root execution, privilege escalation prevention
- **Resource Management:** Optimized requests and limits with JVM considerations

**Professional Notes:**
- The 15% memory buffer (144M vs 128M) indicates understanding of JVM overhead
- Separate readiness and liveness endpoints show microservices best practices
- Topology constraints demonstrate multi-zone deployment planning

### `autoscaler.yaml`
**Purpose:** Implements intelligent auto-scaling based on CPU utilization.

**Key Features:**
- **Asymmetric Scaling:** Different policies for scale-up vs scale-down
- **Stabilization Windows:** Prevents flapping (5min scale-down, 1min scale-up)
- **Percentage-Based Scaling:** More stable than pod count changes
- **Resource Metrics:** CPU utilization targeting for predictable scaling

**Professional Notes:**
- `stabilizationWindowSeconds` usage shows understanding of real-world scaling challenges
- Conservative scale-down protects against traffic spikes after reductions
- v2 API enables future metric expansion beyond CPU

### `service.yaml`
**Status:** *Pending implementation*

**Recommended Implementation:**
```
yaml
apiVersion: v1
kind: Service
metadata:
  name: web-app-service
  namespace: production
spec:
  selector:
    app: web-app
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  type: LoadBalancer
```

</details>

## üõ†Ô∏è Deployment Instructions

### üìã Prerequisites

<details>
<summary><b>üîç Click to expand prerequisites setup</b></summary>

Before starting the deployment, ensure your environment meets these requirements:
```
# Verify kubectl context
kubectl config current-context

# Create production namespace
kubectl create namespace production
```
üí° Tip: Use -o wide flag to see pod distribution across nodes

</details>

#### üöÄ Step 1: Deploy the Application
<details open> <summary><b>üì¶ Application Deployment Commands</b></summary>

```
# ‚ö° Apply deployment configuration
kubectl apply -f deployment.yaml
```
``` 
# ‚úÖ Verify deployment status
kubectl get deployments -n production
kubectl get pods -n production -o wide
```

>üí° Tip: Use -o wide flag to see pod distribution across nodes
  
</details>


#### üìà Step 2: Configure Auto-Scaling
<details open> <summary><b>‚öñÔ∏è HPA Configuration Commands</b></summary>
  
```
# üîÑ Apply HPA configuration
kubectl apply -f autoscaler.yaml
```

```
# üëÅÔ∏è Monitor HPA status in real-time
kubectl get hpa -n production --watch
```
  
>‚ö†Ô∏è Note: The --watch flag provides live updates of scaling events
  
</details>

#### üîó Step 3: (Optional) Create Service
<details open> <summary><b>üåê Service Configuration Commands</b></summary>

```
# üìù Create service.yaml based on recommended template
# ‚ö° Apply service configuration
kubectl apply -f service.yaml
```

```
# üìä Get service details
kubectl get svc -n production
```

</details>

#### üß™ Step 4: Test Scaling

<details open> <summary><b>üìä Load Testing Commands</b></summary>

```  
# üöÄ Generate load (example using hey tool)
hey -z 5m -c 50 http://`service-ip`
```

```
# üëÄ Monitor scaling behavior in real-time
watch kubectl get hpa,pods -n production
```
üîß Tool Required: Install hey with go install 
  
</details>
 


### üìä Performance Characteristics
| Metric | Value | Rationale |
|--|:---:|--|
| üéØ Min Pods | `1` | Cost optimization during low traffic |
| üìà Max Pods | `4` | Determined by load testing |
| ‚ö° CPU Target | `70%` | Balance between utilization and headroom |
| ‚¨ÜÔ∏è Scale-up Speed | `100% per 30s` | Rapid response to traffic spikes |
| ‚¨áÔ∏è Scale-down Speed | `50% per 60s` | Conservative to prevent thrashing |
| üíæ Memory Request | `144M` | 128M + 15% JVM overhead |
| ‚ö†Ô∏è Memory Limit | `160M	` | Additional buffer for spikes |

>üìù Note: All performance characteristics are based on load testing results and can be adjusted based on your specific workload.
  
  
### üîí Security & Compliance

#### ‚úÖ Implemented Security Measures:

<details open> <summary><b>üõ°Ô∏è Detailed Security Configuration</b></summary>
  
| Security Feature | Configuration | Purpose |
|--|:---:|--|
| üë§ Non-root execution | `runAsNonRoot: true` | Prevents running as privileged user |
| üö´ Privilege escalation prevention | `allowPrivilegeEscalation: false` | Blocks privilege elevation attempts |
| üîí Capability reduction | `drop: ["ALL"]` | Removes unnecessary Linux capabilities |
| üÜî Specific user ID | `runAsUser: 1000` | Runs with specific non-root UID |
| üåê Network policy ready | `Labeled selectors` | Enables future network policyimplementation | 
 
</details>
  
  
### üéØ Summary
<details open> <summary><b>üìã Deployment Quick Reference</b></summary>

#### üìù One-Liner Deployment
  
```
kubectl apply -f deployment.yaml && kubectl apply -f autoscaler.yaml
```
  
#### üö® Health Check Commands

```
# Check pod health
kubectl get pods -n production
```

``` 
# View deployment status
kubectl rollout status deployment/web-app -n production
```
  
```
# Check HPA metrics
kubectl describe hpa web-app-hpa -n production
```

#### üìä Monitoring Dashboard Commands
  
```
# Watch all resources
watch kubectl get all -n production
```
  
``` 
# View events
kubectl get events -n production --sort-by='.lastTimestamp'
```

</details>

### üÜò Troubleshooting Tips
#### Quick Fixes:

- If pods aren't starting: `kubectl describe pod -n production -l app=web-app`
- If HPA isn't scaling: `kubectl describe hpa web-app-hpa -n production`
- If service isn't accessible: `kubectl describe svc web-app-service -n production`
